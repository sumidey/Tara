**Tara - Virtual Assistant**

Tara is an interactive virtual assistant built using HTML, CSS, and JavaScript. It leverages the Web Speech API for voice recognition and speech synthesis, enabling users to interact with it using natural language commands. This project demonstrates the integration of voice commands to perform various tasks such as opening websites, telling the time, and more.
*Features*: 
1. Voice Recognition: Tara listens for voice commands using the SpeechRecognition API and processes the input to perform specific actions.
2. Speech Synthesis: It responds to user queries with voice output, providing an engaging interaction.
3. Dynamic Greeting: Based on the time of day, Tara greets users with a tailored message.
4. Command Execution:
a. Opens YouTube when requested.
b. Tells the current time and date.
c. Opens the calculator application.
d. Searches the web for all queries.
5. Interactive UI: The UI dynamically updates to show whether Tara is listening or idle, providing visual feedback to the user.
6. Tech Stack
a. HTML: For the basic structure of the application.
b. CSS: To style the application with a clean and user-friendly interface.
c. JavaScript: Implements the core functionality including voice recognition, speech synthesis, and handling various commands.


**Setup and Deployment**
1. *Clone the repository*
git clone https://github.com/your-username/mira-virtual-assistant.git

2. *Navigate to the project directory:*
cd mira-virtual-assistant

3. *Open index.html in your web browser to start using Tara*.


**How It Works**
1. Voice Activation: Click on the "Click Here to talk with Me" button to activate the voice recognition.
2. Give Commands: Speak any command like "open YouTube" or "what is the time?" and Tara will respond accordingly.
3. Visual Feedback: While listening, a GIF animation is displayed indicating that Tara is processing the user's input.

![photo_6323485014691530091_w](https://github.com/user-attachments/assets/1a3d3b79-54c7-4ecc-9a41-424405c21e8f)


